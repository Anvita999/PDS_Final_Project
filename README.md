# PDS_Final_Project
Offensive Language Detection using distilBERT
Offensive language detection is a common NLP task that involves identifying text containing abusive or derogatory language. To perform this task, one popular approach is to use pre-trained language models such as DistilBERT, a smaller and faster variant of BERT.

DistilBERT is trained on massive amounts of text data, enabling it to understand the meaning and context of words and phrases. To use DistilBERT for offensive language detection, the model is fine-tuned on a labeled dataset of offensive and non-offensive text. During the fine-tuning process, the model learns to identify patterns and features that distinguish between offensive and non-offensive language.

Once the model is trained and fine-tuned, it can be used to classify new text as either offensive or non-offensive with a high level of accuracy. This can be useful in various applications, such as flagging inappropriate comments or messages on social media platforms, or in chatbots to ensure that the conversation remains respectful and appropriate.

In summary, DistilBERT is a powerful tool for offensive language detection that can help promote positive and respectful communication online.
